{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Testing The Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result fo this file is \n",
    "![demo](./Assets/model-demo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code for acheiving above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32  # Image size 32 x 32 px\n",
    "THRESHOLD = 0.90  # only if the model is sure more than 90% then only give the prediction\n",
    "GREEN = (0, 255, 0)  # Green Color\n",
    "RED = (50, 50, 255)  # Red Color\n",
    "FONT = cv2.FONT_HERSHEY_COMPLEX\n",
    "WITH_MASK = 0\n",
    "WITHOUT_MASK = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./Data/mask_detection_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciating the frontal face detector, using [haarcascade_frontalface_default.xml](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml) by openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv2.CascadeClassifier('./Data/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(image):\n",
    "    image = image.astype(\"uint8\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.equalizeHist(image)\n",
    "    image = image / 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_face(image, color, text, x, y, w, h):\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), color, 5)\n",
    "    cv2.rectangle(image, (x, y-40), (x+w, y), color, -2)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text,\n",
    "        (x, y-10),\n",
    "        FONT, 0.75,\n",
    "        (255, 255, 255),\n",
    "        1, cv2.LINE_AA\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking the feed from webcam and checking if the faces in that feed are wearing a mask or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "# run until 'q' or 'Q' is pressed\n",
    "while True:\n",
    "    sucess, frame = webcam.read()  # Read the current frame\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Converting the image to grey for better face recognition\n",
    "    faces = face_detector.detectMultiScale(frame_gray, 1.3, 5)  # Detect for faces in the current frame\n",
    "    \n",
    "    for x, y, w, h in faces: # for x_cor, y_cor, width, height of every face\n",
    "        crop_img = frame[y: y+h, x: x+h]  # crop the frame just to the face using list slicing\n",
    "        img = cv2.resize(crop_img, (IMAGE_SIZE, IMAGE_SIZE)) # Resize the Image to the dimensions\n",
    "        img = image_preprocessing(img)  \n",
    "        img = img.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 1)  \n",
    "        \n",
    "        # Pridict for the face (if it is wearing mask or not)\n",
    "        prediction = model.predict(img)\n",
    "        class_ = np.argmax(prediction)  # getting the index of the hightes prediction\n",
    "        probability = np.max(prediction)\n",
    "        \n",
    "        if probability >= THRESHOLD:\n",
    "            if class_ == WITH_MASK:  # If the face has mask display 'Mask' with green rectangle\n",
    "                highlight_face(frame, GREEN, 'Mask', x, y, w, h)\n",
    "            elif class_ == WITHOUT_MASK:  # If the face does not have mask display 'No Mask' with red rectangle\n",
    "                highlight_face(frame, RED, 'No Mask', x, y, w, h)\n",
    "                \n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "    key = cv2.waitKey(1) # wait for 1 milisecond and capture the key if any pressedf\n",
    "    if key == ord('q') or key == ord('Q'):\n",
    "        break\n",
    "        \n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!, now lets move to the next step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskDetector",
   "language": "python",
   "name": "maskdetector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
